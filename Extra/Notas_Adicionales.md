# Notas Adicionales - AWS AI Practitioner

> ğŸ“… **Fecha de creaciÃ³n:** 8 de diciembre de 2025
>
> Este documento complementa las notas de ReadinessPath con temas no cubiertos previamente.
>
> âš ï¸ PrecauciÃ³n: Este contenido adicional fue generado completamente con IA generativa, NO se debe aceptar el contenido expuesto como fuente de verdad

---

## Tabla de Contenidos

1. [Amazon SageMaker - Servicios Adicionales](#amazon-sagemaker---servicios-adicionales)
2. [MÃ©tricas de ML Tradicional](#mÃ©tricas-de-ml-tradicional)
3. [Amazon Q Business](#amazon-q-business)
4. [Algoritmos de Machine Learning](#algoritmos-de-machine-learning)
5. [Networking - Gateway Endpoints](#networking---gateway-endpoints)
6. [Modelos de ClasificaciÃ³n](#modelos-de-clasificaciÃ³n)
7. [Conceptos TÃ©cnicos Adicionales](#conceptos-tÃ©cnicos-adicionales)

---

## Amazon SageMaker - Servicios Adicionales

### SageMaker Data Wrangler

Herramienta visual para **preparaciÃ³n y transformaciÃ³n de datos** sin escribir cÃ³digo.

**CaracterÃ­sticas principales:**

- Importa datos de mÃºltiples fuentes (S3, Athena, Redshift, etc.)
- Proporciona mÃ¡s de 300 transformaciones predefinidas
- AnÃ¡lisis exploratorio de datos con visualizaciones automÃ¡ticas
- Detecta calidad de datos y sugiere correcciones
- Exporta flujos a notebooks, pipelines o Feature Store

**Casos de uso:**

- Limpieza y normalizaciÃ³n de datasets
- IngenierÃ­a de features visual
- PreparaciÃ³n de datos para entrenamiento

---

### SageMaker Pipelines

Framework para **orquestar flujos de trabajo de ML** de extremo a extremo.

**Componentes:**

| Componente | DescripciÃ³n |
|------------|-------------|
| **Steps** | Pasos individuales (procesamiento, entrenamiento, evaluaciÃ³n) |
| **Parameters** | Variables configurables para el pipeline |
| **Conditions** | LÃ³gica condicional para ramificaciones |
| **Callbacks** | IntegraciÃ³n con servicios externos |

**Beneficios:**

- AutomatizaciÃ³n del ciclo de vida ML
- Reproducibilidad de experimentos
- Versionado de pipelines
- IntegraciÃ³n nativa con otros servicios SageMaker

#### Tipos de Steps en SageMaker Pipelines

| Step | PropÃ³sito | DescripciÃ³n |
|------|-----------|-------------|
| **Processing** | PreparaciÃ³n de datos | Ejecuta trabajos de procesamiento para limpieza, transformaciÃ³n y **feature engineering**. |
| **Training** | Entrenamiento del modelo | Lanza un trabajo de entrenamiento con el algoritmo y datos especificados. |
| **Tuning** | OptimizaciÃ³n de hiperparÃ¡metros | Ejecuta Hyperparameter Tuning Jobs para encontrar la mejor combinaciÃ³n de hiperparÃ¡metros automÃ¡ticamente. |
| **ClarifyCheck** | VerificaciÃ³n de sesgo y explicabilidad | Ejecuta anÃ¡lisis de SageMaker Clarify para detectar sesgos en datos o modelo, y generar reportes de explicabilidad. |

**Flujo tÃ­pico de un pipeline:**

```text
ProcessingStep â†’ TrainingStep â†’ ClarifyCheckStep â†’ RegisterModel
       â†“
   TuningStep (alternativa a TrainingStep para optimizaciÃ³n)
```

**Otros steps disponibles:**

| Step | PropÃ³sito |
|------|-----------|
| **CreateModelStep** | Crea un modelo desplegable a partir de artefactos |
| **RegisterModelStep** | Registra el modelo en Model Registry |
| **ConditionStep** | RamificaciÃ³n condicional (ej: si accuracy > 0.9) |
| **FailStep** | Termina el pipeline con error |
| **CallbackStep** | IntegraciÃ³n con sistemas externos vÃ­a SQS |

---

### SageMaker Model Cards

DocumentaciÃ³n estructurada que describe un modelo ML.

**Contenido tÃ­pico:**

- **InformaciÃ³n del modelo**: Nombre, versiÃ³n, propÃ³sito
- **Uso previsto**: Casos de uso aprobados y restricciones
- **Datos de entrenamiento**: Fuentes, caracterÃ­sticas, sesgos conocidos
- **MÃ©tricas de evaluaciÃ³n**: Rendimiento en diferentes segmentos
- **Consideraciones Ã©ticas**: Limitaciones y riesgos

**PropÃ³sito:** Mejorar la transparencia y gobernanza de modelos ML en producciÃ³n.

---

### SageMaker Model Registry

Repositorio centralizado para **gestionar versiones de modelos**.

**Funcionalidades:**

- Registro de modelos con metadatos
- Estados del modelo: `Pending`, `Approved`, `Rejected`
- Grupos de modelos para organizaciÃ³n
- IntegraciÃ³n con pipelines para despliegue automatizado
- Linaje de modelos (tracking de origen y transformaciones)

**Flujo tÃ­pico:**

1. Entrenar modelo â†’ 2. Registrar en Model Registry â†’ 3. Aprobar â†’ 4. Desplegar a producciÃ³n

---

## MÃ©tricas de ML Tradicional

### MÃ©tricas de RegresiÃ³n

| MÃ©trica | FÃ³rmula | InterpretaciÃ³n |
|---------|---------|----------------|
| **MAE** (Mean Absolute Error) | $\frac{1}{n}\sum\|y_i - \hat{y}_i\|$ | Error promedio absoluto. FÃ¡cil de interpretar. |
| **MAPE** (Mean Absolute Percentage Error) | $\frac{100}{n}\sum\|\frac{y_i - \hat{y}_i}{y_i}\|$ | Error porcentual. Ãštil para comparar entre datasets. |
| **RMSE** (Root Mean Square Error) | $\sqrt{\frac{1}{n}\sum(y_i - \hat{y}_i)^2}$ | Penaliza errores grandes. Misma unidad que la variable objetivo. |
| **RÂ²** (Coeficiente de determinaciÃ³n) | $1 - \frac{SS_{res}}{SS_{tot}}$ | ProporciÃ³n de varianza explicada (0-1). |

**CuÃ¡ndo usar cada una:**

- **MAE**: Cuando todos los errores tienen igual importancia
- **RMSE**: Cuando errores grandes son mÃ¡s problemÃ¡ticos
- **MAPE**: Cuando necesitas comparar modelos en diferentes escalas
- **RÂ²**: Para entender quÃ© tan bien el modelo explica los datos

---

### MÃ©tricas de ClasificaciÃ³n

#### Matriz de ConfusiÃ³n

```text
                    PredicciÃ³n
                 Positivo  Negativo
Real  Positivo     TP        FN
      Negativo     FP        TN
```

- **TP** (True Positive): Correctamente identificado como positivo
- **TN** (True Negative): Correctamente identificado como negativo
- **FP** (False Positive): Incorrectamente identificado como positivo (Error Tipo I)
- **FN** (False Negative): Incorrectamente identificado como negativo (Error Tipo II)

#### MÃ©tricas Derivadas

| MÃ©trica | FÃ³rmula | CuÃ¡ndo usar |
|---------|---------|-------------|
| **Precision** | $\frac{TP}{TP + FP}$ | Cuando FP son costosos (ej: spam, fraude) |
| **Recall** (Sensibilidad) | $\frac{TP}{TP + FN}$ | Cuando FN son costosos (ej: diagnÃ³stico mÃ©dico) |
| **F1 Score** | $2 \times \frac{Precision \times Recall}{Precision + Recall}$ | Balance entre Precision y Recall |
| **Accuracy** | $\frac{TP + TN}{Total}$ | Clases balanceadas |

#### AUC-ROC

- **ROC Curve**: GrÃ¡fica de True Positive Rate vs False Positive Rate
- **AUC** (Area Under Curve): Ãrea bajo la curva ROC (0.5 = aleatorio, 1.0 = perfecto)

**InterpretaciÃ³n del AUC:**

- 0.9 - 1.0: Excelente
- 0.8 - 0.9: Bueno
- 0.7 - 0.8: Aceptable
- 0.6 - 0.7: Pobre
- 0.5 - 0.6: No Ãºtil

---

## Amazon Q Business

Asistente de IA generativa para **empresas** que puede responder preguntas usando datos internos de la organizaciÃ³n.

### CaracterÃ­sticas Principales

| CaracterÃ­stica | DescripciÃ³n |
|----------------|-------------|
| **Conversaciones en lenguaje natural** | Preguntas y respuestas sobre datos empresariales |
| **RAG integrado** | Conecta con fuentes de datos para respuestas contextuales |
| **Plugins de acciones** | Ejecuta tareas en aplicaciones empresariales |
| **Guardrails empresariales** | Control de acceso basado en permisos existentes |

### Fuentes de Datos Soportadas

- Amazon S3
- SharePoint
- Confluence
- Salesforce
- ServiceNow
- Bases de datos (RDS, etc.)
- MÃ¡s de 40 conectores nativos

### Amazon Q in QuickSight

Permite hacer **preguntas en lenguaje natural** sobre dashboards y datos.

**Capacidades:**

- Generar visualizaciones automÃ¡ticamente
- Crear historias de datos
- Responder preguntas sobre mÃ©tricas de negocio
- Sugerir insights relevantes

### Diferencia con Amazon Bedrock

| Aspecto | Amazon Q Business | Amazon Bedrock |
|---------|-------------------|----------------|
| **PropÃ³sito** | Asistente empresarial listo para usar | Plataforma para construir aplicaciones GenAI |
| **ConfiguraciÃ³n** | MÃ­nima (conectar fuentes de datos) | Requiere desarrollo |
| **PersonalizaciÃ³n** | Limitada a configuraciÃ³n | Alta (prompts, fine-tuning, agentes) |
| **Caso de uso** | Productividad empresarial | Aplicaciones personalizadas de IA |

---

## Algoritmos de Machine Learning

### Clustering (Agrupamiento)

Agrupa datos similares sin etiquetas previas (aprendizaje no supervisado).

#### K-Means

- Agrupa datos en **K clusters** predefinidos
- Minimiza la distancia dentro de cada cluster
- Requiere especificar nÃºmero de clusters

**Casos de uso:** SegmentaciÃ³n de clientes, compresiÃ³n de imÃ¡genes

#### Hierarchical Clustering

- Construye una jerarquÃ­a de clusters (dendrograma)
- No requiere especificar K previamente
- Dos enfoques: aglomerativo (bottom-up) o divisivo (top-down)

**Casos de uso:** TaxonomÃ­as, anÃ¡lisis genÃ©tico

---

### Anomaly Detection (DetecciÃ³n de AnomalÃ­as)

Identifica patrones inusuales en los datos.

#### TÃ©cnicas Comunes

| TÃ©cnica | DescripciÃ³n | Caso de uso |
|---------|-------------|-------------|
| **Isolation Forest** | AÃ­sla anomalÃ­as mediante particiones aleatorias | Fraude, intrusiones |
| **One-Class SVM** | Define lÃ­mite de normalidad | Monitoreo de equipos |
| **Autoencoders** | ReconstrucciÃ³n de datos; anomalÃ­as tienen alto error | ImÃ¡genes, series temporales |
| **Statistical methods** | Z-score, IQR para detectar outliers | Datos numÃ©ricos simples |

**Servicios AWS relacionados:**

- **Amazon Lookout for Metrics**: DetecciÃ³n automÃ¡tica de anomalÃ­as en mÃ©tricas
- **Amazon Lookout for Equipment**: Mantenimiento predictivo

---

### Forecasting (PronÃ³stico)

Predice valores futuros basÃ¡ndose en datos histÃ³ricos (series temporales).

#### Algoritmos ClÃ¡sicos

- **ARIMA**: Modelo estadÃ­stico para series estacionarias
- **Exponential Smoothing**: Pondera observaciones recientes

#### Algoritmos de Deep Learning

- **DeepAR** (Amazon): RNN para mÃºltiples series temporales relacionadas
- **Prophet** (Meta): Robusto ante datos faltantes y cambios de tendencia

**Servicio AWS:**

- **Amazon Forecast**: Servicio gestionado para pronÃ³sticos con ML
  - Soporta mÃºltiples algoritmos (DeepAR+, ARIMA, ETS, Prophet)
  - Maneja automÃ¡ticamente features como dÃ­as festivos

---

### Algoritmos de ClasificaciÃ³n

| Algoritmo | Tipo | Fortalezas |
|-----------|------|------------|
| **Random Forest** | Ensemble de Ã¡rboles | Robusto, maneja outliers, interpretable |
| **XGBoost** | Gradient Boosting | Alto rendimiento, usado en competencias |
| **SVM** | Margen mÃ¡ximo | Efectivo en alta dimensiÃ³n |
| **Logistic Regression** | Lineal | Simple, interpretable, baseline sÃ³lido |

---

## Networking - Gateway Endpoints

### VPC Gateway Endpoints

Permiten acceso **privado** a servicios de AWS sin usar internet pÃºblico.

**Servicios soportados:**

- Amazon S3
- DynamoDB

**CaracterÃ­sticas:**

| Aspecto | DescripciÃ³n |
|---------|-------------|
| **Costo** | Sin cargo adicional |
| **Seguridad** | TrÃ¡fico nunca sale de la red de AWS |
| **ConfiguraciÃ³n** | Se aÃ±ade entrada en tabla de rutas |
| **Restricciones** | Solo funciona dentro de la misma regiÃ³n |

### Diferencia: Gateway vs Interface Endpoints

| Tipo | Gateway Endpoint | Interface Endpoint (PrivateLink) |
|------|------------------|----------------------------------|
| **Servicios** | Solo S3 y DynamoDB | MayorÃ­a de servicios AWS |
| **Costo** | Gratis | Cargo por hora y datos |
| **ImplementaciÃ³n** | Entrada en tabla de rutas | ENI en la subnet |
| **Acceso cross-region** | No | SÃ­ (algunos servicios) |

**CuÃ¡ndo usar Gateway Endpoints:**

- Cuando solo necesitas acceso a S3 o DynamoDB
- Para reducir costos de transferencia de datos
- Para mejorar seguridad evitando internet pÃºblico

---

## Modelos de ClasificaciÃ³n

### Binary Classification (ClasificaciÃ³n Binaria)

Predice entre **dos clases** mutuamente excluyentes.

**Ejemplos:**

- Spam / No spam
- Fraude / LegÃ­timo
- Enfermo / Sano

**MÃ©tricas clave:** Precision, Recall, F1, AUC-ROC

**ConsideraciÃ³n importante:** Manejar desbalance de clases (ej: 99% no-fraude, 1% fraude)

**TÃ©cnicas para desbalance:**

- Oversampling (SMOTE)
- Undersampling
- Ajuste de pesos de clase
- Threshold tuning

---

### Multiclass Classification (ClasificaciÃ³n Multiclase)

Predice entre **mÃ¡s de dos clases**.

**Estrategias:**

| Estrategia | DescripciÃ³n |
|------------|-------------|
| **One-vs-All (OvA)** | Entrena N clasificadores binarios (uno por clase) |
| **One-vs-One (OvO)** | Entrena N(N-1)/2 clasificadores (cada par de clases) |
| **Softmax/Multinomial** | Modelo Ãºnico que predice probabilidad de cada clase |

**Ejemplos:**

- ClasificaciÃ³n de documentos por categorÃ­a
- Reconocimiento de dÃ­gitos (0-9)
- ClasificaciÃ³n de sentimiento (positivo, negativo, neutro)

**MÃ©tricas:** Macro/Micro F1, Accuracy, Confusion Matrix multiclase

---

### Image Classification

Clasifica imÃ¡genes completas en categorÃ­as.

**Arquitecturas comunes (CNN):**

- **ResNet**: Conexiones residuales, muy profunda
- **VGG**: Simple, capas convolucionales apiladas
- **EfficientNet**: Balance Ã³ptimo entre precisiÃ³n y eficiencia

**Transfer Learning:**

1. Usar modelo pre-entrenado (ImageNet)
2. Congelar capas base
3. Entrenar solo capas finales con tus datos
4. (Opcional) Fine-tune capas superiores

**Servicio AWS:** Amazon Rekognition Custom Labels para clasificaciÃ³n personalizada sin escribir cÃ³digo ML

---

## Conceptos TÃ©cnicos Adicionales

### Embeddings

Representaciones **vectoriales densas** de datos (texto, imÃ¡genes, etc.) en un espacio de menor dimensiÃ³n.

**Propiedades:**

- Elementos similares tienen vectores cercanos
- Capturan relaciones semÃ¡nticas
- TÃ­picamente 256-4096 dimensiones

**Ejemplo conceptual:**

```text
"rey" - "hombre" + "mujer" â‰ˆ "reina"
```

**Usos:**

- BÃºsqueda semÃ¡ntica
- Sistemas de recomendaciÃ³n
- Clustering de documentos
- Input para RAG

**Servicios AWS:**

- Amazon Bedrock (modelos de embedding como Titan Embeddings)
- Amazon SageMaker (modelos personalizados)

---

### Bases de Datos Vectoriales

Almacenan y buscan eficientemente vectores (embeddings).

**Servicios AWS compatibles:**

| Servicio | DescripciÃ³n |
|----------|-------------|
| **Amazon OpenSearch Service** | Motor de bÃºsqueda con k-NN plugin |
| **Amazon Aurora PostgreSQL** | ExtensiÃ³n pgvector |
| **Amazon Neptune** | Base de datos de grafos con soporte vectorial |
| **Amazon MemoryDB** | Redis compatible con bÃºsqueda vectorial |
| **Amazon DocumentDB** | Soporta bÃºsqueda vectorial |

**Operaciones clave:**

- **IndexaciÃ³n**: Almacenar vectores con metadatos
- **BÃºsqueda k-NN**: Encontrar los K vectores mÃ¡s cercanos
- **Filtrado hÃ­brido**: Combinar bÃºsqueda vectorial con filtros tradicionales

---

### TokenizaciÃ³n

Proceso de dividir texto en unidades mÃ¡s pequeÃ±as (**tokens**) para procesamiento por el modelo.

**Tipos de tokenizaciÃ³n:**

| Tipo | Ejemplo para "playing" | DescripciÃ³n |
|------|------------------------|-------------|
| **Word-level** | `["playing"]` | Palabra completa |
| **Character-level** | `["p","l","a","y","i","n","g"]` | Cada carÃ¡cter |
| **Subword (BPE)** | `["play", "ing"]` | Balance entre ambos |

**Subword tokenization (mÃ¡s usado en LLMs):**

- **BPE** (Byte Pair Encoding): GPT-2, GPT-3
- **WordPiece**: BERT
- **SentencePiece**: T5, LLaMA

**Impacto en costos:**

- Los tokens determinan el costo de API calls
- ~4 caracteres en inglÃ©s â‰ˆ 1 token (aproximado)
- Idiomas con caracteres especiales (espaÃ±ol, chino) pueden usar mÃ¡s tokens

---

### Amazon Bedrock Agents

Permiten que los FMs **ejecuten tareas complejas** de forma autÃ³noma.

**Componentes:**

| Componente | FunciÃ³n |
|------------|---------|
| **Foundation Model** | Razonamiento y planificaciÃ³n |
| **Instructions** | GuÃ­a el comportamiento del agente |
| **Action Groups** | Funciones que el agente puede ejecutar (Lambda) |
| **Knowledge Bases** | Acceso a datos empresariales (RAG) |

**Flujo de trabajo:**

1. Usuario hace una solicitud
2. Agente analiza y planifica pasos necesarios
3. Ejecuta acciones (APIs, consultas a KB)
4. Orquesta mÃºltiples pasos si es necesario
5. Retorna respuesta final

**Casos de uso:**

- Asistentes de servicio al cliente
- AutomatizaciÃ³n de procesos empresariales
- Consultas complejas sobre datos internos

---

### PartyRock

Plataforma de **experimentaciÃ³n con IA generativa** sin cÃ³digo, construida sobre Amazon Bedrock.

**CaracterÃ­sticas:**

- Interfaz visual drag-and-drop
- Acceso gratuito (con lÃ­mites)
- No requiere cuenta de AWS
- Ideal para prototipos rÃ¡pidos y aprendizaje

**Componentes disponibles:**

- GeneraciÃ³n de texto
- GeneraciÃ³n de imÃ¡genes
- Chatbots
- Widgets interactivos

**Limitaciones:**

- No para producciÃ³n
- Opciones de personalizaciÃ³n limitadas
- Sin integraciÃ³n con datos empresariales

**URL:** [partyrock.aws](https://partyrock.aws)

---

## Resumen de Servicios SageMaker

| Servicio | PropÃ³sito | Notas clave |
|----------|-----------|-------------|
| **Data Wrangler** | PreparaciÃ³n de datos | Visual, +300 transformaciones |
| **Pipelines** | OrquestaciÃ³n ML | CI/CD para ML |
| **Model Cards** | DocumentaciÃ³n | Transparencia y gobernanza |
| **Model Registry** | Versionado | Estados: Pending/Approved/Rejected |
| **JumpStart** | FMs pre-entrenados | Acceso rÃ¡pido a modelos |
| **Clarify** | Bias y explicabilidad | Asociado a "sesgo" |
| **Model Monitor** | Monitoreo drift | Asociado a "desviaciones" |
| **Ground Truth** | Etiquetado de datos | RLHF, anotaciÃ³n humana |

---

> ğŸ“ **Nota:** Este documento complementa las notas de los Dominios 1-5 en ReadinessPath. Para temas como RAG, Fine-tuning, RLHF y Prompt Engineering, consultar las notas originales.
